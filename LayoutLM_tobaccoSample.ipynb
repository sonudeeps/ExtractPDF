{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc2e88a2-9d81-4b71-93f6-1f70ffd1e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import requests, zipfile, io\n",
    "from sklearn.utils import shuffle\n",
    "from datasets import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75ddb13a-f500-4eab-9f8d-21e77b215875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADVE': 0, 'Email': 1, 'Form': 2}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"C:/Users/pawvaibh/Downloads/Tobacco\"\n",
    "labels = [label for label in os.listdir(dataset_path)]\n",
    "idx2label = {v: k for v, k in enumerate(labels)}\n",
    "label2idx = {k: v for v, k in enumerate(labels)}\n",
    "label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ace5db6-0ca8-4efd-a757-18d4c9adce69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>C:/Users/pawvaibh/Downloads/Tobacco/ADVE/91689...</td>\n",
       "      <td>ADVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>C:/Users/pawvaibh/Downloads/Tobacco/Email/2714...</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>C:/Users/pawvaibh/Downloads/Tobacco/Form/20309...</td>\n",
       "      <td>Form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C:/Users/pawvaibh/Downloads/Tobacco/ADVE/50259...</td>\n",
       "      <td>ADVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>C:/Users/pawvaibh/Downloads/Tobacco/Form/20308...</td>\n",
       "      <td>Form</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           image_path  label\n",
       "30  C:/Users/pawvaibh/Downloads/Tobacco/ADVE/91689...   ADVE\n",
       "50  C:/Users/pawvaibh/Downloads/Tobacco/Email/2714...  Email\n",
       "68  C:/Users/pawvaibh/Downloads/Tobacco/Form/20309...   Form\n",
       "18  C:/Users/pawvaibh/Downloads/Tobacco/ADVE/50259...   ADVE\n",
       "67  C:/Users/pawvaibh/Downloads/Tobacco/Form/20308...   Form"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame()\n",
    "i=0\n",
    "for label in os.listdir(dataset_path):\n",
    "    count=0\n",
    "    for filename in os.listdir(dataset_path+'/'+label):\n",
    "\n",
    "        if '.ipynb' not in filename and count<200:\n",
    "            data.at[i,'image_path']=dataset_path+'/'+label+'/'+filename\n",
    "            data.at[i,'label']=label\n",
    "            i=i+1\n",
    "            count=count+1\n",
    "\n",
    "\n",
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2405a92-26b2-4725-bf6a-510817522ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Checking Dataset..\n",
      "cannot identify image file 'C:/Users/pawvaibh/Downloads/Tobacco/Email/Thumbs.db'\n",
      "done found 1 corrupt images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[INFO] Checking Dataset..\")\n",
    "c = 0\n",
    "for index, row in data.iterrows():\n",
    "    im_path, label = row\n",
    "    try:\n",
    "        im = Image.open(im_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        c += 1\n",
    "        data.drop(index, inplace=True)\n",
    "        \n",
    "print(f\"done found {c} corrupt images\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60eb73a4-24be-43b6-8058-348f6d511882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[['image_path']]\n",
    "y=data[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e89a865-8af2-4fc2-9e90-4ab149990165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, stratify=y)\n",
    "\n",
    "X_valid,X_test,y_valid,y_test=train_test_split(X_val, y_val, test_size=0.5, stratify=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c236013f-2b59-4e8c-86c6-6d6565d5d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.concat([X_train, y_train], axis=1)\n",
    "valid_data=pd.concat([X_valid, y_valid], axis=1)\n",
    "test_data=pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b7a83e0-00ce-4872-ab34-a7835a24beae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size=len(train_data)\n",
    "validation_size=len(valid_data)\n",
    "test_size=len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1593f362-5343-44b6-8d16-3cfbea327b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:/Users/pawvaibh/AppData/Local/Programs/Tesseract-OCR/tesseract.exe\"\n",
    "\n",
    "def normalize_box(box, width, height):\n",
    "     return [\n",
    "         int(1000 * (box[0] / width)),\n",
    "         int(1000 * (box[1] / height)),\n",
    "         int(1000 * (box[2] / width)),\n",
    "         int(1000 * (box[3] / height)),\n",
    "     ]\n",
    "\n",
    "def apply_ocr(example):\n",
    "        # get the image\n",
    "        image = Image.open(example['image_path'])\n",
    "\n",
    "        width, height = image.size\n",
    "        \n",
    "        # apply ocr to the image \n",
    "        ocr_df = pytesseract.image_to_data(image, output_type='data.frame')\n",
    "        float_cols = ocr_df.select_dtypes('float').columns\n",
    "        ocr_df = ocr_df.dropna().reset_index(drop=True)\n",
    "        ocr_df[float_cols] = ocr_df[float_cols].round(0).astype(int)\n",
    "        ocr_df = ocr_df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "        ocr_df = ocr_df.dropna().reset_index(drop=True)\n",
    "\n",
    "        # get the words and actual (unnormalized) bounding boxes\n",
    "        #words = [word for word in ocr_df.text if str(word) != 'nan'])\n",
    "        words = list(ocr_df.text)\n",
    "        words = [str(w) for w in words]\n",
    "        coordinates = ocr_df[['left', 'top', 'width', 'height']]\n",
    "        actual_boxes = []\n",
    "        for idx, row in coordinates.iterrows():\n",
    "            x, y, w, h = tuple(row) # the row comes in (left, top, width, height) format\n",
    "            actual_box = [x, y, x+w, y+h] # we turn it into (left, top, left+width, top+height) to get the actual box \n",
    "            actual_boxes.append(actual_box)\n",
    "        \n",
    "        # normalize the bounding boxes\n",
    "        boxes = []\n",
    "        for box in actual_boxes:\n",
    "            boxes.append(normalize_box(box, width, height))\n",
    "        \n",
    "        # add as extra columns \n",
    "        assert len(words) == len(boxes)\n",
    "        example['words'] = words\n",
    "        example['bbox'] = boxes\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c45421ac-a541-4c35-adb8-c37261076d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831a81281c0349e9a843475f8d21d703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2cf09f0cecb49e7abe577803d4de55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2d39b64da54bb38fbbdd54758ce2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "updated_train_dataset = train_dataset.map(apply_ocr)\n",
    "\n",
    "valid_dataset = Dataset.from_pandas(valid_data)\n",
    "updated_valid_dataset = valid_dataset.map(apply_ocr)\n",
    "\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "updated_test_dataset = test_dataset.map(apply_ocr)\n",
    "\n",
    "\n",
    "updated_train_dataset=updated_train_dataset.remove_columns('__index_level_0__')\n",
    "updated_valid_dataset=updated_valid_dataset.remove_columns('__index_level_0__')\n",
    "updated_test_dataset=updated_test_dataset.remove_columns('__index_level_0__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6414460f-bb1c-4387-a487-6ea22a0dea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMTokenizer\n",
    "import torch\n",
    "from datasets import Features, Sequence, ClassLabel, Value, Array2D\n",
    "\n",
    "tokenizer = LayoutLMTokenizer.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
    "\n",
    "unique_labels = set([example['label'] for example in updated_train_dataset])\n",
    "\n",
    "# Update class labels\n",
    "class_labels = ClassLabel(names=list(unique_labels))\n",
    "\n",
    "def encode_example(example, max_seq_length=512, pad_token_box=[0, 0, 0, 0]):\n",
    "  words = example['words']\n",
    "  normalized_word_boxes = example['bbox']\n",
    "\n",
    "  assert len(words) == len(normalized_word_boxes)\n",
    "\n",
    "  token_boxes = []\n",
    "  for word, box in zip(words, normalized_word_boxes):\n",
    "      word_tokens = tokenizer.tokenize(word)\n",
    "      token_boxes.extend([box] * len(word_tokens))\n",
    "  \n",
    "  # Truncation of token_boxes\n",
    "  special_tokens_count = 2 \n",
    "  if len(token_boxes) > max_seq_length - special_tokens_count:\n",
    "      token_boxes = token_boxes[: (max_seq_length - special_tokens_count)]\n",
    "  \n",
    "  # add bounding boxes of cls + sep tokens\n",
    "  token_boxes = [[0, 0, 0, 0]] + token_boxes + [[1000, 1000, 1000, 1000]]\n",
    "  \n",
    "  encoding = tokenizer(' '.join(words), padding='max_length', truncation=True)\n",
    "  # Padding of token_boxes up the bounding boxes to the sequence length.\n",
    "  input_ids = tokenizer(' '.join(words), truncation=True)[\"input_ids\"]\n",
    "  padding_length = max_seq_length - len(input_ids)\n",
    "  token_boxes += [pad_token_box] * padding_length\n",
    "  encoding['bbox'] = token_boxes\n",
    "  encoding['label'] = label2idx[example['label']]\n",
    "\n",
    "  assert len(encoding['input_ids']) == max_seq_length\n",
    "  assert len(encoding['attention_mask']) == max_seq_length\n",
    "  assert len(encoding['token_type_ids']) == max_seq_length\n",
    "  assert len(encoding['bbox']) == max_seq_length\n",
    "\n",
    "  return encoding\n",
    "\n",
    "\n",
    "\n",
    "features = Features({\n",
    "    'input_ids': Sequence(feature=Value(dtype='int64')),\n",
    "    'bbox': Array2D(dtype=\"int64\", shape=(512, 4)),\n",
    "    'attention_mask': Sequence(Value(dtype='int64')),\n",
    "    'token_type_ids': Sequence(Value(dtype='int64')),\n",
    "    'label': class_labels,\n",
    "    'image_path': Value(dtype='string'),\n",
    "    'words': Sequence(feature=Value(dtype='string')),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d1059c16-d5bd-4df4-9b61-c426fbe92dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209d6e042d8247738d3600f5705bb150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f93c58c9a3c461f8748b2c8a9255afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a98722f97db4bb483300c869a67b102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/18 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_train_dataset = updated_train_dataset.map(lambda example: encode_example(example), \n",
    "                                      features=features)\n",
    "\n",
    "encoded_train_dataset.set_format(type='torch', columns=['input_ids', 'bbox', 'attention_mask', 'token_type_ids', 'label'])\n",
    "\n",
    "\n",
    "encoded_valid_dataset = updated_valid_dataset.map(lambda example: encode_example(example), \n",
    "                                      features=features)\n",
    "\n",
    "encoded_valid_dataset.set_format(type='torch', columns=['input_ids', 'bbox', 'attention_mask', 'token_type_ids', 'label'])\n",
    "\n",
    "encoded_test_dataset = updated_test_dataset.map(lambda example: encode_example(example), \n",
    "                                      features=features)\n",
    "\n",
    "encoded_test_dataset.set_format(type='torch', columns=['input_ids', 'bbox', 'attention_mask', 'token_type_ids', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f016bb60-c212-4196-9ac8-dfa596ef3099",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(encoded_train_dataset, batch_size=5, shuffle=True)\n",
    "validation_dataloader = torch.utils.data.DataLoader(encoded_valid_dataset, batch_size=2, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(encoded_test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1ace54b-62d1-4c81-9e2a-2065f7f1187d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlm-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LayoutLMForSequenceClassification(\n",
       "  (layoutlm): LayoutLMModel(\n",
       "    (embeddings): LayoutLMEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (x_position_embeddings): Embedding(1024, 768)\n",
       "      (y_position_embeddings): Embedding(1024, 768)\n",
       "      (h_position_embeddings): Embedding(1024, 768)\n",
       "      (w_position_embeddings): Embedding(1024, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): LayoutLMEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x LayoutLMLayer(\n",
       "          (attention): LayoutLMAttention(\n",
       "            (self): LayoutLMSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): LayoutLMSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LayoutLMIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LayoutLMOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): LayoutLMPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import LayoutLMForSequenceClassification\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LayoutLMForSequenceClassification.from_pretrained(\"microsoft/layoutlm-base-uncased\", num_labels=len(label2idx))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e6ae840-f180-4334-9801-41fea40b58b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pawvaibh\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Loss: 2.811434715986252\n",
      "Training accuracy: 51.85185241699219\n",
      "Validation accuracy: 94.44444274902344\n",
      "Epoch: 1\n",
      "Loss: 1.4813955947756767\n",
      "Training accuracy: 87.03704071044922\n",
      "Epoch: 2\n",
      "Loss: 0.6892706342041492\n",
      "Training accuracy: 96.29629516601562\n",
      "Epoch: 3\n",
      "Loss: 0.4380470421165228\n",
      "Training accuracy: 92.59259033203125\n",
      "Epoch: 4\n",
      "Loss: 0.19159172661602497\n",
      "Training accuracy: 98.14814758300781\n",
      "Epoch: 5\n",
      "Loss: 0.07964891055598855\n",
      "Training accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Epoch: 6\n",
      "Loss: 0.041986766969785094\n",
      "Training accuracy: 100.0\n",
      "Epoch: 7\n",
      "Loss: 0.030253490433096886\n",
      "Training accuracy: 100.0\n",
      "Epoch: 8\n",
      "Loss: 0.02449659025296569\n",
      "Training accuracy: 100.0\n",
      "Epoch: 9\n",
      "Loss: 0.020749577903188765\n",
      "Training accuracy: 100.0\n",
      "Epoch: 10\n",
      "Loss: 0.017281885142438114\n",
      "Training accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Epoch: 11\n",
      "Loss: 0.01462728506885469\n",
      "Training accuracy: 100.0\n",
      "Epoch: 12\n",
      "Loss: 0.014223700854927301\n",
      "Training accuracy: 100.0\n",
      "Epoch: 13\n",
      "Loss: 0.011998306261375546\n",
      "Training accuracy: 100.0\n",
      "Epoch: 14\n",
      "Loss: 0.010666407470125705\n",
      "Training accuracy: 100.0\n",
      "Epoch: 15\n",
      "Loss: 0.010541291907429695\n",
      "Training accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Epoch: 16\n",
      "Loss: 0.009331001434475183\n",
      "Training accuracy: 100.0\n",
      "Epoch: 17\n",
      "Loss: 0.00866131199290976\n",
      "Training accuracy: 100.0\n",
      "Epoch: 18\n",
      "Loss: 0.010837121575605124\n",
      "Training accuracy: 100.0\n",
      "Epoch: 19\n",
      "Loss: 0.007938012713566422\n",
      "Training accuracy: 100.0\n",
      "Epoch: 20\n",
      "Loss: 0.007086306868586689\n",
      "Training accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Epoch: 21\n",
      "Loss: 0.006389644113369286\n",
      "Training accuracy: 100.0\n",
      "Epoch: 22\n",
      "Loss: 0.006019889784511179\n",
      "Training accuracy: 100.0\n",
      "Epoch: 23\n",
      "Loss: 0.005747305462136865\n",
      "Training accuracy: 100.0\n",
      "Epoch: 24\n",
      "Loss: 0.005638493166770786\n",
      "Training accuracy: 100.0\n",
      "Epoch: 25\n",
      "Loss: 0.005202873202506453\n",
      "Training accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Epoch: 26\n",
      "Loss: 0.006179153482662514\n",
      "Training accuracy: 100.0\n",
      "Epoch: 27\n",
      "Loss: 0.004718431679066271\n",
      "Training accuracy: 100.0\n",
      "Epoch: 28\n",
      "Loss: 0.004523987096035853\n",
      "Training accuracy: 100.0\n",
      "Epoch: 29\n",
      "Loss: 0.004462132579647005\n",
      "Training accuracy: 100.0\n",
      "Epoch: 30\n",
      "Loss: 0.004016869352199137\n",
      "Training accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Epoch: 31\n",
      "Loss: 0.003842501959297806\n",
      "Training accuracy: 100.0\n",
      "Epoch: 32\n",
      "Loss: 0.0037549783010035753\n",
      "Training accuracy: 100.0\n",
      "Epoch: 33\n",
      "Loss: 0.0035586033191066235\n",
      "Training accuracy: 100.0\n",
      "Epoch: 34\n",
      "Loss: 0.003396361571503803\n",
      "Training accuracy: 100.0\n",
      "Epoch: 35\n",
      "Loss: 0.003187185764545575\n",
      "Training accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Epoch: 36\n",
      "Loss: 0.0031351904035545886\n",
      "Training accuracy: 100.0\n",
      "Epoch: 37\n",
      "Loss: 0.0029169087210902944\n",
      "Training accuracy: 100.0\n",
      "Epoch: 38\n",
      "Loss: 0.0029529173771152273\n",
      "Training accuracy: 100.0\n",
      "Epoch: 39\n",
      "Loss: 0.002718071249546483\n",
      "Training accuracy: 100.0\n",
      "Epoch: 40\n",
      "Loss: 0.0027565493946895003\n",
      "Training accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Epoch: 41\n",
      "Loss: 0.0025619291263865307\n",
      "Training accuracy: 100.0\n",
      "Epoch: 42\n",
      "Loss: 0.0023940311948535964\n",
      "Training accuracy: 100.0\n",
      "Epoch: 43\n",
      "Loss: 0.002505593787645921\n",
      "Training accuracy: 100.0\n",
      "Epoch: 44\n",
      "Loss: 0.0023129458859330043\n",
      "Training accuracy: 100.0\n",
      "Epoch: 45\n",
      "Loss: 0.0022779942955821753\n",
      "Training accuracy: 100.0\n",
      "Validation accuracy: 100.0\n",
      "Epoch: 46\n",
      "Loss: 0.0020980092958780006\n",
      "Training accuracy: 100.0\n",
      "Epoch: 47\n",
      "Loss: 0.002201940631493926\n",
      "Training accuracy: 100.0\n",
      "Epoch: 48\n",
      "Loss: 0.002076606164337136\n",
      "Training accuracy: 100.0\n",
      "Epoch: 49\n",
      "Loss: 0.0021587856608675793\n",
      "Training accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "global_step = 0\n",
    "num_train_epochs = 50\n",
    "t_total = len(train_dataloader) * num_train_epochs # total number of training steps \n",
    "\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "  print(\"Epoch:\", epoch)\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  model.train()\n",
    "  for batch in train_dataloader:\n",
    "      input_ids = batch[\"input_ids\"].to(device)\n",
    "      bbox = batch[\"bbox\"].to(device)\n",
    "      attention_mask = batch[\"attention_mask\"].to(device)\n",
    "      token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "      labels = batch[\"label\"].to(device)\n",
    "\n",
    "      # forward pass\n",
    "      outputs = model(input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids,\n",
    "                      labels=labels)\n",
    "      loss = outputs.loss\n",
    "\n",
    "      running_loss += loss.item()\n",
    "      predictions = outputs.logits.argmax(-1)\n",
    "      correct += (predictions == labels).float().sum()\n",
    "\n",
    "      # backward pass to get the gradients \n",
    "      loss.backward()\n",
    "\n",
    "      # update\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "      global_step += 1\n",
    "  \n",
    "  print(\"Loss:\", running_loss / batch[\"input_ids\"].shape[0])\n",
    "  accuracy = 100 * correct / train_size\n",
    "  print(\"Training accuracy:\", accuracy.item())\n",
    "    \n",
    "  if epoch%5==0:\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for batch in validation_dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        bbox = batch[\"bbox\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        outputs = model(input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        predictions = outputs.logits.argmax(-1)\n",
    "        correct += (predictions == labels).float().sum()\n",
    "\n",
    "    accuracy = 100 * correct / validation_size\n",
    "    print(\"Validation accuracy:\", accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f56ef4da-ccae-440c-bb80-9389af6b2a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([2])\n",
      "tensor([2])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([2])\n",
      "tensor([2])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([2])\n",
      "tensor([2])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([2])\n",
      "tensor([2])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([2])\n",
      "tensor([2])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([2])\n",
      "tensor([2])\n",
      "tensor([1])\n",
      "tensor([1])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([0])\n",
      "tensor([2])\n",
      "tensor([2])\n",
      "Testing accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "labels_output=[]\n",
    "predictions_output=[]\n",
    "\n",
    "\n",
    "correct = 0\n",
    "for batch in test_dataloader:\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    bbox = batch[\"bbox\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    token_type_ids = batch[\"token_type_ids\"].to(device)\n",
    "    labels = batch[\"label\"].to(device)\n",
    "    outputs = model(input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    predictions = outputs.logits.argmax(-1)\n",
    "    print(labels)\n",
    "    print(predictions)\n",
    "    correct += (predictions == labels).float().sum()\n",
    "\n",
    "\n",
    "accuracy = 100 * correct / test_size\n",
    "print(\"Testing accuracy:\", accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
